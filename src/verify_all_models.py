#!/usr/bin/env python3
"""
Comprehensive verification of all trained models (Q-learning, DQN, PPO).
"""

import warnings
warnings.filterwarnings('ignore')

import os
import sys
import pickle
import numpy as np
import torch
from datetime import datetime

# Add gym_scaling to path
sys.path.insert(0, os.getcwd())

from gym_scaling.envs.scaling_env import ScalingEnv, INPUTS


def verify_qlearning_model(model_path, model_name):
    """Verify Q-learning model."""
    
    print(f"\n{'='*70}")
    print(f"Verifying: {model_name}")
    print(f"Path: {model_path}")
    print(f"{'='*70}")
    
    # Check if file exists
    if not os.path.exists(model_path):
        print(f"âŒ Model file not found!")
        return False
    
    file_size = os.path.getsize(model_path) / 1024  # KB
    print(f"âœ“ Model file exists ({file_size:.2f} KB)")
    
    # Try to load the model
    try:
        with open(model_path, 'rb') as f:
            q_table = pickle.load(f)
        print(f"âœ“ Q-table loaded successfully")
        print(f"  - Type: {type(q_table)}")
        print(f"  - Size: {len(q_table)} states")
        
        # Check Q-table structure
        if len(q_table) == 0:
            print(f"âŒ Q-table is empty!")
            return False
        
        # Sample some Q-values
        sample_states = list(q_table.keys())[:3]
        print(f"  - Sample states and Q-values:")
        for state in sample_states:
            print(f"    State {state}: {q_table[state]}")
            
    except Exception as e:
        print(f"âŒ Failed to load Q-table: {e}")
        return False
    
    # Test with environment
    print(f"\nðŸ§ª Running test episode...")
    env = ScalingEnv()
    env.scaling_env_options['input'] = INPUTS['SINE_CURVE']
    env.change_rate = 1
    
    def discretize_state(obs):
        """Discretize continuous observation."""
        queue_size, num_instances, influx, load, cost = obs
        queue_bucket = min(int(queue_size / 10), 10)
        instance_bucket = min(int(num_instances), 10)
        influx_bucket = min(int(influx / 10), 10)
        load_bucket = min(int(load / 20), 5)
        return (queue_bucket, instance_bucket, influx_bucket, load_bucket)
    
    obs = env.reset()
    total_reward = 0
    steps = 0
    max_steps = 100
    
    for step in range(max_steps):
        state = discretize_state(obs)
        
        # Get action from Q-table
        if state in q_table:
            action = np.argmax(q_table[state])
        else:
            action = 1  # Default: no change
        
        obs, reward, done, info = env.step(action)
        total_reward += reward
        steps += 1
        
        if done:
            break
    
    print(f"âœ“ Test episode completed")
    print(f"  - Steps: {steps}")
    print(f"  - Total reward: {total_reward:.2f}")
    print(f"  - Final cost: ${env.total_cost:.2f}")
    
    env.close()
    
    print(f"\n{'='*70}")
    print(f"âœ… {model_name} verification PASSED!")
    print(f"{'='*70}\n")
    
    return True


def verify_sb3_model(model_path, model_name, model_type="DQN"):
    """Verify Stable-Baselines3 model (DQN or PPO)."""
    
    print(f"\n{'='*70}")
    print(f"Verifying: {model_name}")
    print(f"Path: {model_path}")
    print(f"{'='*70}")
    
    # Check if file exists
    if not os.path.exists(model_path):
        print(f"âŒ Model file not found!")
        return False
    
    file_size = os.path.getsize(model_path) / (1024 * 1024)  # MB
    print(f"âœ“ Model file exists ({file_size:.2f} MB)")
    
    # Try to load the model
    try:
        if model_type == "DQN":
            from stable_baselines3 import DQN
            model = DQN.load(model_path)
        else:  # PPO
            from stable_baselines3 import PPO
            model = PPO.load(model_path)
            
        print(f"âœ“ {model_type} model loaded successfully")
        print(f"  - Policy: {model.policy.__class__.__name__}")
        print(f"  - Device: {model.device}")
        
        # Check if model has been trained
        if hasattr(model, 'num_timesteps'):
            print(f"  - Training timesteps: {model.num_timesteps:,}")
            
    except Exception as e:
        print(f"âŒ Failed to load model: {e}")
        return False
    
    # Test with environment (need Gymnasium wrapper for SB3)
    print(f"\nðŸ§ª Running test episode...")
    
    try:
        import gymnasium as gym
        from gymnasium import spaces
        
        class GymnasiumWrapper(gym.Env):
            def __init__(self, env):
                super().__init__()
                self.env = env
                self.action_space = spaces.Discrete(env.num_actions)
                self.observation_space = spaces.Box(
                    low=0.0, high=np.inf, shape=(5,), dtype=np.float32
                )
            
            def reset(self, seed=None, options=None):
                if seed is not None:
                    np.random.seed(seed)
                obs = self.env.reset()
                return obs.astype(np.float32), {}
            
            def step(self, action):
                obs, reward, done, info = self.env.step(action)
                return obs.astype(np.float32), reward, done, False, info
            
            def close(self):
                return self.env.close()
            
            @property
            def total_cost(self):
                return self.env.total_cost
        
        env = ScalingEnv()
        env.scaling_env_options['input'] = INPUTS['SINE_CURVE']
        env.change_rate = 1
        env = GymnasiumWrapper(env)
        
        obs, _ = env.reset()
        total_reward = 0
        steps = 0
        max_steps = 100
        actions_taken = []
        
        for step in range(max_steps):
            action, _ = model.predict(obs, deterministic=True)
            actions_taken.append(int(action))
            obs, reward, done, truncated, info = env.step(action)
            total_reward += reward
            steps += 1
            
            if done or truncated:
                break
        
        # Analyze actions
        action_counts = {0: 0, 1: 0, 2: 0}
        for a in actions_taken:
            action_counts[a] = action_counts.get(a, 0) + 1
        
        print(f"âœ“ Test episode completed")
        print(f"  - Steps: {steps}")
        print(f"  - Total reward: {total_reward:.2f}")
        print(f"  - Final cost: ${env.total_cost:.2f}")
        print(f"  - Actions: Remove={action_counts[0]}, Hold={action_counts[1]}, Add={action_counts[2]}")
        
        env.close()
        
    except Exception as e:
        print(f"âš ï¸  Could not run test episode: {e}")
        print(f"   (Model loaded successfully, but environment test failed)")
    
    print(f"\n{'='*70}")
    print(f"âœ… {model_name} verification PASSED!")
    print(f"{'='*70}\n")
    
    return True


def main():
    """Verify all trained models."""
    
    print("\n" + "ðŸ” " * 35)
    print("COMPREHENSIVE MODEL VERIFICATION")
    print("Project: Smart AutoScaler RL Agent")
    print("ðŸ” " * 35)
    
    results = []
    
    # Q-learning models
    print("\n" + "="*70)
    print("1. Q-LEARNING MODELS")
    print("="*70)
    
    qlearning_models = [
        ("models/qlearning_extended_20251129_175127.pkl", "Q-Learning (Latest)"),
        ("models/qlearning_extended_20251129_175034.pkl", "Q-Learning (Earlier)"),
        ("models/scaling_model.pkl", "Q-Learning (Original)"),
    ]
    
    for model_path, model_name in qlearning_models:
        if os.path.exists(model_path):
            success = verify_qlearning_model(model_path, model_name)
            results.append((model_name, success, "Q-Learning"))
        else:
            print(f"\nâš ï¸  Skipping {model_name} - file not found")
            results.append((model_name, False, "Q-Learning"))
    
    # DQN models
    print("\n" + "="*70)
    print("2. DQN MODELS")
    print("="*70)
    
    dqn_models = [
        ("models/dqn_m4gpu_sine_curve_20251129_174102_final.zip", "DQN Final (10k steps)"),
        ("models/checkpoints/dqn_m4gpu_sine_curve_20251129_174102_10000_steps.zip", "DQN Checkpoint (10k)"),
        ("models/best/best_model.zip", "DQN Best Model"),
    ]
    
    for model_path, model_name in dqn_models:
        if os.path.exists(model_path):
            success = verify_sb3_model(model_path, model_name, "DQN")
            results.append((model_name, success, "DQN"))
        else:
            print(f"\nâš ï¸  Skipping {model_name} - file not found")
            results.append((model_name, False, "DQN"))
    
    # PPO models
    print("\n" + "="*70)
    print("3. PPO MODELS")
    print("="*70)
    
    ppo_models = [
        ("models/ppo_simple_20251129_180558.zip", "PPO Final (100k steps)"),
        ("models/checkpoints/ppo_simple_20251129_180558_100000_steps.zip", "PPO Checkpoint (100k)"),
        ("models/checkpoints/ppo_simple_20251129_180558_80000_steps.zip", "PPO Checkpoint (80k)"),
    ]
    
    for model_path, model_name in ppo_models:
        if os.path.exists(model_path):
            success = verify_sb3_model(model_path, model_name, "PPO")
            results.append((model_name, success, "PPO"))
        else:
            print(f"\nâš ï¸  Skipping {model_name} - file not found")
            results.append((model_name, False, "PPO"))
    
    # Summary
    print("\n" + "="*70)
    print("VERIFICATION SUMMARY")
    print("="*70)
    
    by_type = {"Q-Learning": [], "DQN": [], "PPO": []}
    for model_name, success, model_type in results:
        by_type[model_type].append((model_name, success))
    
    for model_type in ["Q-Learning", "DQN", "PPO"]:
        print(f"\n{model_type}:")
        for model_name, success in by_type[model_type]:
            status = "âœ… PASS" if success else "âŒ FAIL"
            print(f"  {status} - {model_name}")
    
    # Overall assessment
    passed = sum(1 for _, success, _ in results if success)
    total = len(results)
    
    print("\n" + "="*70)
    print(f"OVERALL: {passed}/{total} models verified successfully")
    
    if passed >= 3:  # At least one of each type
        print("\nðŸŽ‰ SUCCESS! You have working models for all three RL methods!")
        print("   âœ“ Q-Learning: Tabular RL baseline")
        print("   âœ“ DQN: Deep Q-Network with experience replay")
        print("   âœ“ PPO: Policy gradient method")
        print("\nYour project is ready for evaluation and comparison!")
    else:
        print("\nâš ï¸  Some models are missing or failed verification")
        print("   Consider retraining failed models")
    
    print("="*70 + "\n")
    
    return passed >= 3


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
